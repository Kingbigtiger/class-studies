{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6   6  \n",
       "1      5        3      3     1     1      3        4   5   5   6  \n",
       "2      4        3      2     2     3      3       10   7   8  10  \n",
       "3      3        2      2     1     1      5        2  15  14  15  \n",
       "4      4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zf = zipfile.ZipFile(\"student.zip\")\n",
    "df = pd.read_csv(zf.open('student-mat.csv'),sep = \";\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['school',\n",
       " 'sex',\n",
       " 'age',\n",
       " 'address',\n",
       " 'famsize',\n",
       " 'Pstatus',\n",
       " 'Medu',\n",
       " 'Fedu',\n",
       " 'Mjob',\n",
       " 'Fjob',\n",
       " 'reason',\n",
       " 'guardian',\n",
       " 'traveltime',\n",
       " 'studytime',\n",
       " 'failures',\n",
       " 'schoolsup',\n",
       " 'famsup',\n",
       " 'paid',\n",
       " 'activities',\n",
       " 'nursery',\n",
       " 'higher',\n",
       " 'internet',\n",
       " 'romantic',\n",
       " 'famrel',\n",
       " 'freetime',\n",
       " 'goout',\n",
       " 'Dalc',\n",
       " 'Walc',\n",
       " 'health',\n",
       " 'absences',\n",
       " 'G1',\n",
       " 'G2',\n",
       " 'G3']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dumb = pd.get_dummies(df[['sex', 'higher', 'famsup']],drop_first=True)\n",
    "df_dumb.head()\n",
    "df_newc = pd.concat([df_dumb,df[['age']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prettier plots are better.\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Bivariate relationships of predictors to higher education, Family Support, and Sex Male outcome.\n",
    "sns.boxplot(x=\"sex_M\", y=\"higher_yes\", data=df_dumb)\n",
    "plt.show()\n",
    "sns.boxplot(x=\"sex_M\", y=\"famsup_yes\", data=df_dumb)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Relationship between predictors.\n",
    "sns.regplot(x='higher_yes', y='famsup_yes', data=df_dumb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.172277\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:             higher_yes   No. Observations:                  395\n",
      "Model:                          Logit   Df Residuals:                      393\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 20 Apr 2019   Pseudo R-squ.:                     inf\n",
      "Time:                        11:33:46   Log-Likelihood:                -68.050\n",
      "converged:                       True   LL-Null:                        0.0000\n",
      "                                        LLR p-value:                     1.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "sex_M          1.5731      0.274      5.732      0.000       1.035       2.111\n",
      "famsup_yes     2.9677      0.364      8.164      0.000       2.255       3.680\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\postgres\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:488: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "C:\\Users\\postgres\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:488: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "C:\\Users\\postgres\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:3313: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 1 - self.llf/self.llnull\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Declare predictors.\n",
    "X_statsmod = df_newc[['higher_yes']]\n",
    "\n",
    "# The Statsmodels formulation requires a column with constant value 1 that\n",
    "# will act as the intercept.\n",
    "# X_statsmod['intercept'] = 1 \n",
    "\n",
    "# Declare and fit the model.\n",
    "logit = sm.Logit(X_statsmod, df_newc[['sex_M', 'famsup_yes']])\n",
    "result = logit.fit()\n",
    "\n",
    "# Lots of information about the model and its coefficients, but the\n",
    "# accuracy rate for predictions is missing.\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_statsmod.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients\n",
      "[[-1.45952331  0.72634928]]\n",
      "[3.49452836]\n",
      "\n",
      " Accuracy by Grade Point 1 and Grade point 2\n",
      "higher_yes   0    1\n",
      "row_0              \n",
      "1           20  375\n",
      "\n",
      " Percentage accuracy\n",
      "0.9493670886075949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\postgres\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1e9)\n",
    "y = df_newc['higher_yes']\n",
    "X = df_newc[['sex_M', 'famsup_yes']]\n",
    "\n",
    "# Fit the model.\n",
    "fit = lr.fit(X, y)\n",
    "\n",
    "# Display.\n",
    "print('Coefficients')\n",
    "print(fit.coef_)\n",
    "print(fit.intercept_)\n",
    "pred_y_sklearn = lr.predict(X)\n",
    "\n",
    "print('\\n Accuracy by Grade Point 1 and Grade point 2')\n",
    "print(pd.crosstab(pred_y_sklearn, y))\n",
    "\n",
    "print('\\n Percentage accuracy')\n",
    "print(lr.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6   6  \n",
       "1      5        3      3     1     1      3        4   5   5   6  \n",
       "2      4        3      2     2     3      3       10   7   8  10  \n",
       "3      3        2      2     1     1      5        2  15  14  15  \n",
       "4      4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zf = zipfile.ZipFile(\"student.zip\")\n",
    "df = pd.read_csv(zf.open('student-mat.csv'),sep = \";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dumb = pd.get_dummies(df[['sex', 'higher', 'famsup']],drop_first=True)\n",
    "df_dumb.head()\n",
    "df_new3 = pd.concat([df_dumb,df[['G3']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared simple model:\n",
      "0.10115575968974244\n"
     ]
    }
   ],
   "source": [
    "# Define the training and test sizes.\n",
    "trainsize = int(df_new3.shape[0] / 2)\n",
    "df_test = df_new3.iloc[trainsize:, :].copy()\n",
    "df_train = df_new3.iloc[:trainsize, :].copy()\n",
    "\n",
    "# Set up the regression model to predict defaults using all other\n",
    "# variables as features.\n",
    "regr1 = linear_model.Ridge()\n",
    "Y_train = df_train['G3'].values.reshape(-1, 1)\n",
    "X_train = df_train.loc[:, ~(df_train.columns).isin(['G3'])]\n",
    "regr1.fit(X_train, Y_train)\n",
    "print('\\nR-squared simple model:')\n",
    "print(regr1.score(X_train, Y_train))\n",
    "\n",
    "#Store the parameter estimates.\n",
    "origparams = np.append(regr1.coef_, regr1.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared complex model:\n",
      "0.11461012021216499\n",
      "\n",
      "Parameter Estimates for the same predictors for the small model and large model:\n",
      "[[1.644 -4.944]\n",
      " [5.279 0.816]\n",
      " [-0.835 -1.344]\n",
      " [5.266 10.344]]\n"
     ]
    }
   ],
   "source": [
    "# Make new features to capture potential quadratic and cubic relationships\n",
    "# between the features.\n",
    "df_train['sex_higher'] = df_train['sex_M'] * df_train['higher_yes']\n",
    "df_train['sex_famsup'] = df_train['sex_M'] * df_train['famsup_yes']\n",
    "df_train['higher_famsup'] = df_train['higher_yes'] * df_train['famsup_yes']\n",
    "\n",
    "\n",
    "# Re-run the model with the new features.\n",
    "regrBig = linear_model.LinearRegression()\n",
    "X_train2 = df_train.loc[:, ~(df_train.columns).isin(['G3'])]\n",
    "regrBig.fit(X_train2, Y_train)\n",
    "print('\\nR-squared complex model:')\n",
    "print(regrBig.score(X_train2, Y_train))\n",
    "\n",
    "# Store the new parameter estimates for the same features.\n",
    "newparams = np.append(\n",
    "    regrBig.coef_[0,0:(len(origparams)-1)],\n",
    "    regrBig.intercept_)\n",
    "\n",
    "print('\\nParameter Estimates for the same predictors for the small model '\n",
    "      'and large model:')\n",
    "compare = np.column_stack((origparams, newparams))\n",
    "prettycompare = np.array2string(\n",
    "    compare,\n",
    "    formatter={'float_kind':'{0:.3f}'.format})\n",
    "print(prettycompare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03825825501850444\n",
      "[2.79051242 8.48579306 0.73760069]\n",
      "0.039003051094489205\n",
      "\n",
      "Parameter Estimates for the same predictors for the small modeland large model:\n",
      "[[2.791 2.668]\n",
      " [8.486 8.377]\n",
      " [0.738 1.239]]\n"
     ]
    }
   ],
   "source": [
    "ridgeregr = linear_model.Ridge(alpha=10, fit_intercept=False) \n",
    "ridgeregr.fit(X_train, Y_train)\n",
    "print(ridgeregr.score(X_train, Y_train))\n",
    "origparams = ridgeregr.coef_[0]\n",
    "print(origparams)\n",
    "\n",
    "ridgeregrBig = linear_model.Ridge(alpha=10, fit_intercept=False)\n",
    "ridgeregrBig.fit(X_train2, Y_train)\n",
    "print(ridgeregrBig.score(X_train2, Y_train))\n",
    "newparams = ridgeregrBig.coef_[0, 0:len(origparams)]\n",
    "\n",
    "print('\\nParameter Estimates for the same predictors for the small model'\n",
    "      'and large model:')\n",
    "compare = np.column_stack((origparams, newparams))\n",
    "prettycompare = np.array2string(\n",
    "    compare,\n",
    "    formatter={'float_kind':'{0:.3f}'.format})\n",
    "print(prettycompare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6   6  \n",
       "1      5        3      3     1     1      3        4   5   5   6  \n",
       "2      4        3      2     2     3      3       10   7   8  10  \n",
       "3      3        2      2     1     1      5        2  15  14  15  \n",
       "4      4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zf = zipfile.ZipFile(\"student.zip\")\n",
    "df = pd.read_csv(zf.open('student-mat.csv'),sep = \";\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dumb = pd.get_dummies(df[['sex', 'higher', 'famsup']],drop_first=True)\n",
    "df_dumb.head()\n",
    "df_new4 = pd.concat([df_dumb,df[['G3']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training and test sizes.\n",
    "trainsize = int(df_new4.shape[0] / 2)\n",
    "df_test = df_new4.iloc[trainsize:, :].copy()\n",
    "df_train = df_new4.iloc[:trainsize, :].copy()\n",
    "\n",
    "Y_train = df_train['G3'].values.reshape(-1, 1)\n",
    "X_train = df_train.loc[:, ~(df_train.columns).isin(['G3'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new features to capture potential quadratic and cubic relationships\n",
    "# between the features.\n",
    "df_train['sex_higher'] = df_train['sex_M'] * df_train['higher_yes']\n",
    "df_train['sex_famsup'] = df_train['sex_M'] * df_train['famsup_yes']\n",
    "df_train['higher_famsup'] = df_train['higher_yes'] * df_train['famsup_yes']\n",
    "\n",
    "\n",
    "X_train2 = df_train.loc[:, ~(df_train.columns).isin(['G3'])]\n",
    "\n",
    "# Test the simpler model with smaller coefficients.\n",
    "Y_test = df_test['G3'].values.reshape(-1, 1)\n",
    "X_test = df_test.loc[:, ~(df_test.columns).isin(['G3'])]\n",
    "\n",
    "X_train2 = df_train.loc[:, ~(df_train.columns).isin(['G3'])]\n",
    "\n",
    "# Test the simpler model with smaller coefficients.\n",
    "Y_test = df_test['G3'].values.reshape(-1, 1)\n",
    "X_test = df_test.loc[:, ~(df_test.columns).isin(['G3'])]\n",
    "\n",
    "# Test the more complex model with larger coefficients.\n",
    "df_train['sex_higher'] = df_train['sex_M'] * df_train['higher_yes']\n",
    "df_train['sex_famsup'] = df_train['sex_M'] * df_train['famsup_yes']\n",
    "df_train['higher_famsup'] = df_train['higher_yes'] * df_train['famsup_yes']\n",
    "\n",
    "X_test2 = df_test.loc[:, ~(df_test.columns).isin(['G3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² for the model with few features:\n",
      "0.0\n",
      "\n",
      "Parameter estimates for the model with few features:\n",
      "[ 0.          0.         -0.         10.59390863]\n",
      "\n",
      "R² for the model with many features:\n",
      "0.04004431029593769\n",
      "\n",
      "Parameter estimates for the model with many features:\n",
      "[ 0.          0.         -0.          0.9276419   0.         -0.\n",
      " 10.14656863]\n"
     ]
    }
   ],
   "source": [
    "# Small number of parameters.\n",
    "lass = linear_model.Lasso(alpha=.35)\n",
    "lassfit = lass.fit(X_train, Y_train)\n",
    "print('R² for the model with few features:')\n",
    "print(lass.score(X_train, Y_train))\n",
    "origparams = np.append(lassfit.coef_, lassfit.intercept_)\n",
    "print('\\nParameter estimates for the model with few features:')\n",
    "print(origparams)\n",
    "\n",
    "# Large number of parameters.\n",
    "lassBig = linear_model.Lasso(alpha=.35)\n",
    "lassBig.fit(X_train2, Y_train)\n",
    "print('\\nR² for the model with many features:')\n",
    "print(lassBig.score(X_train2, Y_train))\n",
    "origparams = np.append(lassBig.coef_, lassBig.intercept_)\n",
    "print('\\nParameter estimates for the model with many features:')\n",
    "print(origparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sex_M  higher_yes  famsup_yes  sex_higher  sex_famsup  higher_famsup\n",
      "0        0           1           0           0           0              0\n",
      "1        0           1           1           0           0              1\n",
      "2        0           1           0           0           0              0\n",
      "3        0           1           1           0           0              1\n",
      "4        0           1           1           0           0              1\n",
      "5        1           1           1           1           1              1\n",
      "6        1           1           0           1           0              0\n",
      "7        0           1           1           0           0              1\n",
      "8        1           1           1           1           1              1\n",
      "9        1           1           1           1           1              1\n",
      "10       0           1           1           0           0              1\n",
      "11       0           1           1           0           0              1\n",
      "12       1           1           1           1           1              1\n",
      "13       1           1           1           1           1              1\n",
      "14       1           1           1           1           1              1\n",
      "15       0           1           1           0           0              1\n",
      "16       0           1           1           0           0              1\n",
      "17       0           1           1           0           0              1\n",
      "18       1           1           1           1           1              1\n",
      "19       1           1           0           1           0              0\n",
      "20       1           1           0           1           0              0\n",
      "21       1           1           1           1           1              1\n",
      "22       1           1           0           1           0              0\n",
      "23       1           1           1           1           1              1\n",
      "24       0           1           1           0           0              1\n",
      "25       0           1           1           0           0              1\n",
      "26       1           1           1           1           1              1\n",
      "27       1           1           0           1           0              0\n",
      "28       1           1           1           1           1              1\n",
      "29       1           1           1           1           1              1\n",
      "..     ...         ...         ...         ...         ...            ...\n",
      "167      0           1           0           0           0              0\n",
      "168      0           1           1           0           0              1\n",
      "169      0           1           1           0           0              1\n",
      "170      1           1           1           1           1              1\n",
      "171      1           1           1           1           1              1\n",
      "172      1           1           1           1           1              1\n",
      "173      0           1           0           0           0              0\n",
      "174      0           1           1           0           0              1\n",
      "175      1           1           0           1           0              0\n",
      "176      0           1           0           0           0              0\n",
      "177      1           1           0           1           0              0\n",
      "178      1           1           1           1           1              1\n",
      "179      1           1           1           1           1              1\n",
      "180      1           1           1           1           1              1\n",
      "181      1           1           0           1           0              0\n",
      "182      0           1           1           0           0              1\n",
      "183      0           1           1           0           0              1\n",
      "184      0           1           1           0           0              1\n",
      "185      1           1           1           1           1              1\n",
      "186      1           1           1           1           1              1\n",
      "187      1           1           0           1           0              0\n",
      "188      0           1           1           0           0              1\n",
      "189      1           1           0           1           0              0\n",
      "190      0           1           0           0           0              0\n",
      "191      0           1           0           0           0              0\n",
      "192      1           1           0           1           0              0\n",
      "193      1           1           1           1           1              1\n",
      "194      1           1           0           1           0              0\n",
      "195      0           1           0           0           0              0\n",
      "196      1           1           0           1           0              0\n",
      "\n",
      "[197 rows x 6 columns]\n",
      "[[ 6]\n",
      " [ 6]\n",
      " [10]\n",
      " [15]\n",
      " [10]\n",
      " [15]\n",
      " [11]\n",
      " [ 6]\n",
      " [19]\n",
      " [15]\n",
      " [ 9]\n",
      " [12]\n",
      " [14]\n",
      " [11]\n",
      " [16]\n",
      " [14]\n",
      " [14]\n",
      " [10]\n",
      " [ 5]\n",
      " [10]\n",
      " [15]\n",
      " [15]\n",
      " [16]\n",
      " [12]\n",
      " [ 8]\n",
      " [ 8]\n",
      " [11]\n",
      " [15]\n",
      " [11]\n",
      " [11]\n",
      " [12]\n",
      " [17]\n",
      " [16]\n",
      " [12]\n",
      " [15]\n",
      " [ 6]\n",
      " [18]\n",
      " [15]\n",
      " [11]\n",
      " [13]\n",
      " [11]\n",
      " [12]\n",
      " [18]\n",
      " [11]\n",
      " [ 9]\n",
      " [ 6]\n",
      " [11]\n",
      " [20]\n",
      " [14]\n",
      " [ 7]\n",
      " [13]\n",
      " [13]\n",
      " [10]\n",
      " [11]\n",
      " [13]\n",
      " [10]\n",
      " [15]\n",
      " [15]\n",
      " [ 9]\n",
      " [16]\n",
      " [11]\n",
      " [11]\n",
      " [ 9]\n",
      " [ 9]\n",
      " [10]\n",
      " [15]\n",
      " [12]\n",
      " [ 6]\n",
      " [ 8]\n",
      " [16]\n",
      " [15]\n",
      " [10]\n",
      " [ 5]\n",
      " [14]\n",
      " [11]\n",
      " [10]\n",
      " [10]\n",
      " [11]\n",
      " [10]\n",
      " [ 5]\n",
      " [12]\n",
      " [11]\n",
      " [ 6]\n",
      " [15]\n",
      " [10]\n",
      " [ 8]\n",
      " [ 6]\n",
      " [14]\n",
      " [10]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [18]\n",
      " [ 6]\n",
      " [10]\n",
      " [14]\n",
      " [10]\n",
      " [15]\n",
      " [10]\n",
      " [14]\n",
      " [ 8]\n",
      " [ 5]\n",
      " [17]\n",
      " [14]\n",
      " [ 6]\n",
      " [18]\n",
      " [11]\n",
      " [ 8]\n",
      " [18]\n",
      " [13]\n",
      " [16]\n",
      " [19]\n",
      " [10]\n",
      " [13]\n",
      " [19]\n",
      " [ 9]\n",
      " [16]\n",
      " [14]\n",
      " [13]\n",
      " [ 8]\n",
      " [13]\n",
      " [15]\n",
      " [15]\n",
      " [13]\n",
      " [13]\n",
      " [ 8]\n",
      " [12]\n",
      " [11]\n",
      " [ 9]\n",
      " [ 0]\n",
      " [18]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [12]\n",
      " [11]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [12]\n",
      " [15]\n",
      " [ 0]\n",
      " [ 9]\n",
      " [11]\n",
      " [13]\n",
      " [ 0]\n",
      " [11]\n",
      " [ 0]\n",
      " [11]\n",
      " [ 0]\n",
      " [10]\n",
      " [ 0]\n",
      " [14]\n",
      " [10]\n",
      " [ 0]\n",
      " [12]\n",
      " [ 8]\n",
      " [13]\n",
      " [10]\n",
      " [15]\n",
      " [12]\n",
      " [ 0]\n",
      " [ 7]\n",
      " [ 0]\n",
      " [10]\n",
      " [ 7]\n",
      " [12]\n",
      " [10]\n",
      " [16]\n",
      " [ 0]\n",
      " [14]\n",
      " [ 0]\n",
      " [16]\n",
      " [10]\n",
      " [ 0]\n",
      " [ 9]\n",
      " [ 9]\n",
      " [11]\n",
      " [ 6]\n",
      " [ 9]\n",
      " [11]\n",
      " [ 8]\n",
      " [12]\n",
      " [17]\n",
      " [ 8]\n",
      " [12]\n",
      " [11]\n",
      " [11]\n",
      " [15]\n",
      " [ 9]\n",
      " [10]\n",
      " [13]\n",
      " [ 9]\n",
      " [ 8]\n",
      " [10]\n",
      " [14]\n",
      " [15]\n",
      " [16]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train2)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.006283119149905758\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (198,3) and (6,) not aligned: 3 (dim 1) != 6 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-1b45b0565ca1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlassBig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         return r2_score(y, self.predict(X), sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    331\u001b[0m                         multioutput='variance_weighted')\n\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \"\"\"\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    803\u001b[0m                                    dense_output=True) + self.intercept_\n\u001b[0;32m    804\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mElasticNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m--> 198\u001b[1;33m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (198,3) and (6,) not aligned: 3 (dim 1) != 6 (dim 0)"
     ]
    }
   ],
   "source": [
    "print(lass.score(X_test, Y_test))\n",
    "\n",
    "print(lassBig.score(X_test2, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
